
# ğŸ“„ Agentic RAG Chatbot

An interactive document-based Q&A system powered by LangChain agents, Azure OpenAI embeddings, FAISS vector store, and a clean Streamlit interface.

---

## ğŸš€ Features

- âœ… Upload and parse files (PDF, DOCX, PPTX, CSV, TXT, MD)
- âœ… Extract text using `IngestionAgent`
- âœ… Embed text and perform vector search using `RetrievalAgent`
- âœ… Generate contextual answers via `LLMResponseAgent` using Azure OpenAI
- âœ… Modular design using MCP (Model Context Protocol) for agent communication
- âœ… Streamlit-based UI with live chat history and collapsible context

---

## ğŸ§  Tech Stack

| Tool | Purpose |
|------|---------|
| **LangChain** | Agent framework and vector store interface |
| **Azure OpenAI** | Embeddings & GPT-4 LLM |
| **FAISS** | Vector similarity search |
| **Streamlit** | UI for document upload and chat |
| **Python** | Core development |
| **Pydantic** | Data validation for agents |

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app.py                        # Streamlit UI
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion_agent.py        # Handles parsing uploaded files
â”‚   â”œâ”€â”€ retrieval_agent.py        # Embeds text & retrieves relevant chunks
â”‚   â””â”€â”€ llm_response_agent.py     # Calls OpenAI with context & query
â”œâ”€â”€ assets/                       # Icons, diagrams, and demo screenshots
â”‚   â”œâ”€â”€ demo_upload_ui.png        # Snapshot of file upload section
â”‚   â”œâ”€â”€ demo_question_input.png   # Snapshot of question input UI
â”‚   â”œâ”€â”€ demo_source_context.png   # Snapshot showing retrieved context
â”‚   â”œâ”€â”€ demo_answer_display.png   # Snapshot showing LLM response
â”‚   â””â”€â”€ architecture.png          # Project architecture diagram
â”œâ”€â”€ .env                          # Azure API keys and endpoints
â”œâ”€â”€ requirements.txt              # Required Python packages
â””â”€â”€ README.md                     # Project overview and instructions

```

---

## âš™ï¸ How It Works

1. **Upload File** â†’ Parses and sends text via `IngestionAgent`
2. **Retrieve Chunks** â†’ Embeds and retrieves with `RetrievalAgent`
3. **Generate Answer** â†’ Uses GPT via `LLMResponseAgent`
4. **Display** â†’ Shows answer with source context

Agents communicate using **MCP messages** like:
```json
{
  "type": "RETRIEVAL_RESULT",
  "sender": "RetrievalAgent",
  "receiver": "LLMResponseAgent",
  "trace_id": "rag-457",
  "payload": {
    "retrieved_context": [...],
    "query": "What KPIs were tracked in Q1?"
  }
}
```

---

## ğŸ” .env Configuration

```env
EMBEDDING_AZURE_OPENAI_API_KEY=your_api_key
EMBEDDING_AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
OPENAI_API_VERSION=2023-05-15
EMBEDDING_AZURE_OPENAI_DEPLOYMENT_NAME=your-embedding-deployment
CHAT_AZURE_OPENAI_DEPLOYMENT_NAME=your-chat-deployment
```

---

## â–¶ï¸ Run Locally

1. **Clone the repo**
```bash
git clone https://github.com/yourusername/agentic-rag-chatbot.git
cd agentic-rag-chatbot
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Add your `.env` file**

4. **Run the app**
```bash
streamlit run app.py
```

---

## Demo snaps
![image alt](https://github.com/ChemalaHussainaiah16/Agentic-RAG-Chatbot/blob/160c2a46079a3f39bc04275840e91d96cfa8910f/Photo1%20(1).png)
![image alt]()
![image alt]()
![image alt]()
![image alt]()

## ğŸ™‹â€â™‚ï¸ Author

**[Chemala Hussainaiah]**  
Final year B.Tech student at Marwadi University  
ğŸ”— [LinkedIn](www.linkedin.com/in/chemala-hussainaiah-95bab7359)  
ğŸ“§ chemalahussainaiah@gmail.com

---

## â­ Future Improvements

- âœ… PDF chunk highlighting in output
- âœ… Add Chat History persistence
- ğŸŸ¡ Support multiple document queries
- ğŸŸ¡ Add authentication and logging

---

## ğŸ§  Inspired by

- LangChain + OpenAI agent architecture
- Azure AI Studio + FAISS document RAG demos

---

## ğŸ“ License

This project is under the MIT License.
